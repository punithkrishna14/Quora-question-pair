{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model for Quora Question Pairs's Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv(\"train.csv\")\n",
    " \n",
    "# encode questions to unicode\n",
    "df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- It is a better choice to go further with TF-IDF scoring. \n",
    "- For TF-IDF, I used scikit-learn (heaven of ML).  \n",
    "- It provides TfIdfVectorizer which does everything you need.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\". \n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores. - The below code does this for \"question1\" and \"question2\" columns.\n",
    "- This is how we use Spacy for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [08:32<00:00, 788.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# exctract word2vec vectors\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "vecs1 = []\n",
    "for qu1 in tqdm(list(df['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    mean_vec1 = np.zeros([len(doc1), 300])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df['q1_feats_m'] = list(vecs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [08:34<00:00, 785.93it/s]\n"
     ]
    }
   ],
   "source": [
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc2), 300])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df['q2_feats_m'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reading the Features (Explored in EDA) like : preprocessing features and NLP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "q1_m=df['q1_feats_m'].values\n",
    "q2_m=df['q2_feats_m'].values\n",
    "\n",
    "\n",
    "#df['cosine']=np.array([cosine_similarity(q1_m[i],q2_m[i]) for i in range(0,len(q1_m))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "#df['eucld_dis'] = pairwise_distances(q1_m,q2_m , metric='euclidean', n_jobs=1)\n",
    "#df['eucld_dis'] = df.apply(lambda row: pairwise_distances(row[\"q1_feats_m\"].values, row[\"q2_feats_m\"].values, metric='euclidean', n_jobs=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['cosine_dis'] = df.apply(lambda row: pairwise_distances(row[\"q1_feats_m\"], row[\"q2_feats_m\"], metric='cosine', n_jobs=1), axis=1)\n",
    "\n",
    "df['manhattan_dis'] = df.apply(lambda row: pairwise_distances(row[\"q1_feats_m\"], row[\"q2_feats_m\"], metric='manhattan', n_jobs=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "df1['braycurtis_dis'] = df.apply(lambda row: scipy.spatial.distance.braycurtis(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['canberra_dis'] = df.apply(lambda row: scipy.spatial.distance.canberra(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['chebyshev_dis'] = df.apply(lambda row: scipy.spatial.distance.chebyshev(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['cityblock_dis'] = df.apply(lambda row: scipy.spatial.distance.cityblock(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['correlation_dis'] = df.apply(lambda row: scipy.spatial.distance.correlation(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['cosine_dis'] = df.apply(lambda row: scipy.spatial.distance.cosine(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['euclidean_dis'] = df.apply(lambda row: scipy.spatial.distance.euclidean(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "#df['mahalanobis_dis'] = df.apply(lambda row: scipy.spatial.distance.mahalanobis(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['minkowski_dis'] = df.apply(lambda row: scipy.spatial.distance.minkowski(row[\"q1_feats_m\"], row[\"q2_feats_m\"], 3), axis=1)\n",
    "\n",
    "#df['seuclidean_dis'] = df.apply(lambda row: scipy.spatial.distance.seuclidean(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['sqeuclidean_dis'] = df.apply(lambda row: scipy.spatial.distance.sqeuclidean(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "#df['wminkowski_dis'] = df.apply(lambda row: scipy.spatial.distance.wminkowski(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n",
    "\n",
    "df1['hamming_dis'] = df.apply(lambda row: scipy.spatial.distance.hamming(row[\"q1_feats_m\"], row[\"q2_feats_m\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>braycurtis_dis</th>\n",
       "      <th>canberra_dis</th>\n",
       "      <th>chebyshev_dis</th>\n",
       "      <th>cityblock_dis</th>\n",
       "      <th>correlation_dis</th>\n",
       "      <th>cosine_dis</th>\n",
       "      <th>euclidean_dis</th>\n",
       "      <th>minkowski_dis</th>\n",
       "      <th>sqeuclidean_dis</th>\n",
       "      <th>hamming_dis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033526</td>\n",
       "      <td>29.418519</td>\n",
       "      <td>6.501952</td>\n",
       "      <td>158.116874</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>12.871938</td>\n",
       "      <td>7.496870</td>\n",
       "      <td>165.686783</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515475</td>\n",
       "      <td>173.066755</td>\n",
       "      <td>79.473514</td>\n",
       "      <td>1468.718965</td>\n",
       "      <td>0.209615</td>\n",
       "      <td>0.211893</td>\n",
       "      <td>135.934008</td>\n",
       "      <td>88.790428</td>\n",
       "      <td>18478.054406</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282911</td>\n",
       "      <td>128.748397</td>\n",
       "      <td>18.491902</td>\n",
       "      <td>1137.846965</td>\n",
       "      <td>0.078117</td>\n",
       "      <td>0.078275</td>\n",
       "      <td>85.572404</td>\n",
       "      <td>39.782522</td>\n",
       "      <td>7322.636355</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.668339</td>\n",
       "      <td>199.018340</td>\n",
       "      <td>50.365853</td>\n",
       "      <td>1821.904978</td>\n",
       "      <td>0.280281</td>\n",
       "      <td>0.282520</td>\n",
       "      <td>143.185040</td>\n",
       "      <td>73.653511</td>\n",
       "      <td>20501.955571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.453698</td>\n",
       "      <td>166.270553</td>\n",
       "      <td>40.897270</td>\n",
       "      <td>2083.473957</td>\n",
       "      <td>0.201416</td>\n",
       "      <td>0.202895</td>\n",
       "      <td>149.786324</td>\n",
       "      <td>68.844244</td>\n",
       "      <td>22435.942710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   braycurtis_dis  canberra_dis  chebyshev_dis  cityblock_dis  \\\n",
       "0        0.033526     29.418519       6.501952     158.116874   \n",
       "1        0.515475    173.066755      79.473514    1468.718965   \n",
       "2        0.282911    128.748397      18.491902    1137.846965   \n",
       "3        0.668339    199.018340      50.365853    1821.904978   \n",
       "4        0.453698    166.270553      40.897270    2083.473957   \n",
       "\n",
       "   correlation_dis  cosine_dis  euclidean_dis  minkowski_dis  sqeuclidean_dis  \\\n",
       "0         0.001011    0.001012      12.871938       7.496870       165.686783   \n",
       "1         0.209615    0.211893     135.934008      88.790428     18478.054406   \n",
       "2         0.078117    0.078275      85.572404      39.782522      7322.636355   \n",
       "3         0.280281    0.282520     143.185040      73.653511     20501.955571   \n",
       "4         0.201416    0.202895     149.786324      68.844244     22435.942710   \n",
       "\n",
       "   hamming_dis  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#word2vec_model.init_sims(replace=True) \n",
    "# normalizes vectors\n",
    "# Compute WMD as normal.\n",
    "#distance = word2vec_model.wmdistance(\"string 1\".split(), \"string 2\".split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyemd import wmdistance\n",
    "#df1['word_mover_dis'] = df.apply(lambda row: word2vec_model.wmdistance(row['question1'].split(), row['question2'].split()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>braycurtis_dis</th>\n",
       "      <th>canberra_dis</th>\n",
       "      <th>chebyshev_dis</th>\n",
       "      <th>cityblock_dis</th>\n",
       "      <th>correlation_dis</th>\n",
       "      <th>cosine_dis</th>\n",
       "      <th>euclidean_dis</th>\n",
       "      <th>minkowski_dis</th>\n",
       "      <th>sqeuclidean_dis</th>\n",
       "      <th>hamming_dis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033526</td>\n",
       "      <td>29.418519</td>\n",
       "      <td>6.501952</td>\n",
       "      <td>158.116874</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>12.871938</td>\n",
       "      <td>7.496870</td>\n",
       "      <td>165.686783</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.515475</td>\n",
       "      <td>173.066755</td>\n",
       "      <td>79.473514</td>\n",
       "      <td>1468.718965</td>\n",
       "      <td>0.209615</td>\n",
       "      <td>0.211893</td>\n",
       "      <td>135.934008</td>\n",
       "      <td>88.790428</td>\n",
       "      <td>18478.054406</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282911</td>\n",
       "      <td>128.748397</td>\n",
       "      <td>18.491902</td>\n",
       "      <td>1137.846965</td>\n",
       "      <td>0.078117</td>\n",
       "      <td>0.078275</td>\n",
       "      <td>85.572404</td>\n",
       "      <td>39.782522</td>\n",
       "      <td>7322.636355</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.668339</td>\n",
       "      <td>199.018340</td>\n",
       "      <td>50.365853</td>\n",
       "      <td>1821.904978</td>\n",
       "      <td>0.280281</td>\n",
       "      <td>0.282520</td>\n",
       "      <td>143.185040</td>\n",
       "      <td>73.653511</td>\n",
       "      <td>20501.955571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.453698</td>\n",
       "      <td>166.270553</td>\n",
       "      <td>40.897270</td>\n",
       "      <td>2083.473957</td>\n",
       "      <td>0.201416</td>\n",
       "      <td>0.202895</td>\n",
       "      <td>149.786324</td>\n",
       "      <td>68.844244</td>\n",
       "      <td>22435.942710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   braycurtis_dis  canberra_dis  chebyshev_dis  cityblock_dis  \\\n",
       "0        0.033526     29.418519       6.501952     158.116874   \n",
       "1        0.515475    173.066755      79.473514    1468.718965   \n",
       "2        0.282911    128.748397      18.491902    1137.846965   \n",
       "3        0.668339    199.018340      50.365853    1821.904978   \n",
       "4        0.453698    166.270553      40.897270    2083.473957   \n",
       "\n",
       "   correlation_dis  cosine_dis  euclidean_dis  minkowski_dis  sqeuclidean_dis  \\\n",
       "0         0.001011    0.001012      12.871938       7.496870       165.686783   \n",
       "1         0.209615    0.211893     135.934008      88.790428     18478.054406   \n",
       "2         0.078117    0.078275      85.572404      39.782522      7322.636355   \n",
       "3         0.280281    0.282520     143.185040      73.653511     20501.955571   \n",
       "4         0.201416    0.202895     149.786324      68.844244     22435.942710   \n",
       "\n",
       "   hamming_dis  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.to_csv(\"W2V_vec_distance_features_train1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy.linalg\n",
    "#df[\"q1_inverse\"] = df.apply(lambda row: numpy.linalg.inv(row[\"q1_feats_m\"]), axis=1)\n",
    "#df[\"q2_inverse\"] = df.apply(lambda row: numpy.linalg.inv(row[\"q2_feats_m\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv(\"wtov_mean_features_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "dfnlp = pd.read_csv(\"df1_nlp1_features.csv\")\n",
    "dfppro = pd.read_csv(\"df1_preprocessing1_features.csv\")\n",
    "dfw2v = pd.read_csv(\"W2V_vec_distance_features_train1.csv\")\n",
    "\n",
    "#dfnlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "      <th>capital_1</th>\n",
       "      <th>capital_2</th>\n",
       "      <th>capital_total</th>\n",
       "      <th>capital_diff</th>\n",
       "      <th>bigram_common</th>\n",
       "      <th>bigram_total</th>\n",
       "      <th>bigram_ratio</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>tfidf_unigram_word_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>(0, 77556)\\t0.0756699844518\\n  (0, 35701)\\t0...</td>\n",
       "      <td>0.966742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>(0, 77556)\\t0.0701848729964\\n  (0, 35701)\\t0...</td>\n",
       "      <td>0.650728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>(0, 70831)\\t0.0540481138459\\n  (0, 10064)\\t0...</td>\n",
       "      <td>0.301877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(0, 35701)\\t0.0668356636523\\n  (0, 70831)\\t0...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>(0, 33839)\\t0.116120577565\\n  (0, 78429)\\t0....</td>\n",
       "      <td>0.293379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  word_Common  \\\n",
       "0          1          1     66     57          14          12         10.0   \n",
       "1          4          1     51     88           8          13          4.0   \n",
       "2          1          1     73     59          14          10          4.0   \n",
       "3          1          1     50     65          11           9          0.0   \n",
       "4          3          1     76     39          13           7          2.0   \n",
       "\n",
       "   word_Total  word_share  freq_q1+q2  freq_q1-q2  capital_1  capital_2  \\\n",
       "0        23.0    0.434783           2           0        1.0        1.0   \n",
       "1        20.0    0.200000           5           3        5.0        5.0   \n",
       "2        24.0    0.166667           2           0        5.0        5.0   \n",
       "3        19.0    0.000000           2           0        4.0        1.0   \n",
       "4        20.0    0.100000           4           2        1.0        1.0   \n",
       "\n",
       "   capital_total  capital_diff  bigram_common  bigram_total  bigram_ratio  \\\n",
       "0            2.0           0.0           11.0          15.0      0.733333   \n",
       "1           10.0           0.0            6.0          23.0      0.260870   \n",
       "2           10.0           0.0            1.0          23.0      0.043478   \n",
       "3            5.0           3.0            0.0          23.0      0.000000   \n",
       "4            2.0           0.0            0.0          22.0      0.000000   \n",
       "\n",
       "                                               tfidf  tfidf_unigram_word_match  \n",
       "0    (0, 77556)\\t0.0756699844518\\n  (0, 35701)\\t0...                  0.966742  \n",
       "1    (0, 77556)\\t0.0701848729964\\n  (0, 35701)\\t0...                  0.650728  \n",
       "2    (0, 70831)\\t0.0540481138459\\n  (0, 10064)\\t0...                  0.301877  \n",
       "3    (0, 35701)\\t0.0668356636523\\n  (0, 70831)\\t0...                  0.000000  \n",
       "4    (0, 33839)\\t0.116120577565\\n  (0, 78429)\\t0....                  0.293379  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfppro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  \\\n",
       "0  0.999980  0.833319  0.999983  0.999983  0.916659  0.785709           0.0   \n",
       "1  0.799984  0.399996  0.749981  0.599988  0.699993  0.466664           0.0   \n",
       "2  0.399992  0.333328  0.399992  0.249997  0.399996  0.285712           0.0   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000           0.0   \n",
       "4  0.399992  0.199998  0.999950  0.666644  0.571420  0.307690           0.0   \n",
       "\n",
       "   first_word_eq  abs_len_diff  mean_len  token_set_ratio  token_sort_ratio  \\\n",
       "0            1.0           2.0      13.0              100                93   \n",
       "1            1.0           5.0      12.0               86                63   \n",
       "2            1.0           4.0      12.0               63                63   \n",
       "3            0.0           2.0      12.0               28                24   \n",
       "4            1.0           6.0      10.0               67                47   \n",
       "\n",
       "   fuzz_ratio  fuzz_partial_ratio  longest_substr_ratio  \n",
       "0          93                 100                     0  \n",
       "1          66                  75                     0  \n",
       "2          43                  47                     0  \n",
       "3           9                  14                     0  \n",
       "4          35                  56                     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 80)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_feats = np.concatenate()\n",
    "\n",
    "#frames = [df, dfppro, dfnlp]\n",
    "\n",
    "df_all_features = pd.concat([dfppro, dfnlp, dfw2v], axis=1)\n",
    "df_all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>...</th>\n",
       "      <th>chebyshev_dis</th>\n",
       "      <th>cityblock_dis</th>\n",
       "      <th>correlation_dis</th>\n",
       "      <th>cosine_dis</th>\n",
       "      <th>euclidean_dis</th>\n",
       "      <th>minkowski_dis</th>\n",
       "      <th>sqeuclidean_dis</th>\n",
       "      <th>hamming_dis</th>\n",
       "      <th>q1_pr</th>\n",
       "      <th>q2_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.501952</td>\n",
       "      <td>158.116874</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>12.871938</td>\n",
       "      <td>7.496870</td>\n",
       "      <td>165.686783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.608480e-07</td>\n",
       "      <td>3.047631e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>79.473514</td>\n",
       "      <td>1468.718965</td>\n",
       "      <td>0.209615</td>\n",
       "      <td>0.211893</td>\n",
       "      <td>135.934008</td>\n",
       "      <td>88.790428</td>\n",
       "      <td>18478.054406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.198776e-07</td>\n",
       "      <td>3.097268e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>18.491902</td>\n",
       "      <td>1137.846965</td>\n",
       "      <td>0.078117</td>\n",
       "      <td>0.078275</td>\n",
       "      <td>85.572404</td>\n",
       "      <td>39.782522</td>\n",
       "      <td>7322.636355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.049200e-07</td>\n",
       "      <td>1.609126e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>50.365853</td>\n",
       "      <td>1821.904978</td>\n",
       "      <td>0.280281</td>\n",
       "      <td>0.282520</td>\n",
       "      <td>143.185040</td>\n",
       "      <td>73.653511</td>\n",
       "      <td>20501.955571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.088105e-07</td>\n",
       "      <td>2.088105e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>40.897270</td>\n",
       "      <td>2083.473957</td>\n",
       "      <td>0.201416</td>\n",
       "      <td>0.202895</td>\n",
       "      <td>149.786324</td>\n",
       "      <td>68.844244</td>\n",
       "      <td>22435.942710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.406708e-07</td>\n",
       "      <td>1.278450e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  word_Common  \\\n",
       "0          1          1     66     57          14          12         10.0   \n",
       "1          4          1     51     88           8          13          4.0   \n",
       "2          1          1     73     59          14          10          4.0   \n",
       "3          1          1     50     65          11           9          0.0   \n",
       "4          3          1     76     39          13           7          2.0   \n",
       "\n",
       "   word_Total  word_share  freq_q1+q2      ...       chebyshev_dis  \\\n",
       "0        23.0    0.434783           2      ...            6.501952   \n",
       "1        20.0    0.200000           5      ...           79.473514   \n",
       "2        24.0    0.166667           2      ...           18.491902   \n",
       "3        19.0    0.000000           2      ...           50.365853   \n",
       "4        20.0    0.100000           4      ...           40.897270   \n",
       "\n",
       "   cityblock_dis  correlation_dis  cosine_dis  euclidean_dis  minkowski_dis  \\\n",
       "0     158.116874         0.001011    0.001012      12.871938       7.496870   \n",
       "1    1468.718965         0.209615    0.211893     135.934008      88.790428   \n",
       "2    1137.846965         0.078117    0.078275      85.572404      39.782522   \n",
       "3    1821.904978         0.280281    0.282520     143.185040      73.653511   \n",
       "4    2083.473957         0.201416    0.202895     149.786324      68.844244   \n",
       "\n",
       "   sqeuclidean_dis  hamming_dis         q1_pr         q2_pr  \n",
       "0       165.686783          1.0  1.608480e-07  3.047631e-07  \n",
       "1     18478.054406          1.0  8.198776e-07  3.097268e-07  \n",
       "2      7322.636355          1.0  3.049200e-07  1.609126e-07  \n",
       "3     20501.955571          1.0  2.088105e-07  2.088105e-07  \n",
       "4     22435.942710          1.0  3.406708e-07  1.278450e-07  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#W2V Question1 Vector\n",
    "Q1_vec = df['q1_feats_m'].values\n",
    "#W2V Question2 Vector\n",
    "Q2_vec = df['q2_feats_m'].values\n",
    "#Features Extracted in EDA\n",
    "feat_80 = df_all_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 2, 3, 4, 3, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "c = [3,4]\n",
    "np.concatenate((a,b,c))\n",
    "\n",
    "sklearn.metrics.pairwise.pairwise_distances(X, Y=None, metric=’euclidean’, n_jobs=1, **kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a Single vector with the combination of all 2 W2V vectors and all Features(26)\n",
    "- \"features\"  : is the combined vectorof length 626 of all 3 thinngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "for i in range(0,len(Q1_vec)):\n",
    "    Q1 = Q1_vec[i]\n",
    "    Q2 = Q2_vec[i]\n",
    "    f = feat_80[i]\n",
    "    features.append(np.concatenate((Q1,Q2,f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680\n",
      "404290\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features)\n",
    "print len(features[0])\n",
    "#print Q1_vec[0][0:15]\n",
    "#print Q2_vec[0][0:15]\n",
    "#print feat_26[0]\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"lbl\" = Lables Values or class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbl = df[\"is_duplicate\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Splitting the train and test data into 80% and 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshan_excellence/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "#test_proportion of 3 would mean 1/3 so 33% test and 67% train\n",
    "def shuffle(matrix, target, test_proportion):\n",
    "    ratio = matrix.shape[0]/test_proportion\n",
    "    X_train = matrix[ratio:,:]\n",
    "    X_test =  matrix[:ratio,:]\n",
    "    Y_train = target[ratio:]\n",
    "    Y_test =  target[:ratio]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "X_train, X_test, Y_train, Y_test = shuffle(features, lbl, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-Implementing Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "best_params_logreg = []\n",
    "parameters = {'loss':['log'],'penalty':['l1','l2','elasticnet'],'alpha':[0.001,0.01,0.1,1,10,20,30,40,50,60,70,80,90,100], 'n_jobs':[-1]}\n",
    "\n",
    "clf = SGDClassifier()\n",
    "clf = GridSearchCV(clf,parameters,cv = 5)\n",
    "clf.fit(X_train,Y_train)\n",
    "best_params_logreg.append(clf.best_params_)\n",
    "print best_params_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do a test with cross validation\n",
    "clf = SGDClassifier(loss= 'log',penalty = 'elasticnet',alpha = 0.01,n_jobs = -1)\n",
    "#choose best parameters\n",
    "score = cross_val_score(clf,X_train,Y_train,cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777294759058\n"
     ]
    }
   ],
   "source": [
    "#cross validation score. Test it\n",
    "print sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test set Prediction\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "conf_log_ref = confusion_matrix(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48108  2599]\n",
      " [15690 14461]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print conf_log_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 77.3813351802\n"
     ]
    }
   ],
   "source": [
    "true = conf_log_ref[0][0]+conf_log_ref[1][1]\n",
    "false = conf_log_ref[0][1]+conf_log_ref[1][0]\n",
    "print \"Test accuracy:\",float(true)*100/(true+false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAHvCAYAAACbuiM9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nimoRERERkUb6P4EiISStsCM1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82f7c1e050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 84.7655334115\n",
      "Recall : 47.9619249776\n"
     ]
    }
   ],
   "source": [
    "score_Log_reg = []\n",
    "\n",
    "#ROC for a given alpha for log reg\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute ROC curve and ROC area for each class\n",
    "probs = clf.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(Y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#Plot ROC\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Precision and recall\n",
    "tn = conf_log_ref[0,0]; fp = conf_log_ref[0,1]; fn = conf_log_ref[1,0]; tp = conf_log_ref[1,1];\n",
    "\n",
    "precision = 100*float(tp)/(tp+fp)\n",
    "recall = 100*float(tp)/(tp+fn)\n",
    "\n",
    "print \"Precision :\",precision\n",
    "print \"Recall :\",recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using XG-Boost for better result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XG-Boost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.684874\tvalid-logloss:0.68485\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 20 rounds.\n",
      "[10]\ttrain-logloss:0.61497\tvalid-logloss:0.614961\n",
      "[20]\ttrain-logloss:0.564574\tvalid-logloss:0.564663\n",
      "[30]\ttrain-logloss:0.526446\tvalid-logloss:0.526749\n",
      "[40]\ttrain-logloss:0.497318\tvalid-logloss:0.497832\n",
      "[50]\ttrain-logloss:0.474221\tvalid-logloss:0.474874\n",
      "[60]\ttrain-logloss:0.455786\tvalid-logloss:0.456649\n",
      "[70]\ttrain-logloss:0.441134\tvalid-logloss:0.442104\n",
      "[80]\ttrain-logloss:0.429209\tvalid-logloss:0.430262\n",
      "[90]\ttrain-logloss:0.419703\tvalid-logloss:0.4208\n",
      "[100]\ttrain-logloss:0.411767\tvalid-logloss:0.412922\n",
      "[110]\ttrain-logloss:0.405076\tvalid-logloss:0.406258\n",
      "[120]\ttrain-logloss:0.399539\tvalid-logloss:0.400765\n",
      "[130]\ttrain-logloss:0.394769\tvalid-logloss:0.396019\n",
      "[140]\ttrain-logloss:0.390956\tvalid-logloss:0.392238\n",
      "[150]\ttrain-logloss:0.387527\tvalid-logloss:0.388846\n",
      "[160]\ttrain-logloss:0.384669\tvalid-logloss:0.38604\n",
      "[170]\ttrain-logloss:0.381978\tvalid-logloss:0.383362\n",
      "[180]\ttrain-logloss:0.379621\tvalid-logloss:0.381041\n",
      "[190]\ttrain-logloss:0.377462\tvalid-logloss:0.378893\n",
      "[200]\ttrain-logloss:0.375461\tvalid-logloss:0.37693\n",
      "[210]\ttrain-logloss:0.373675\tvalid-logloss:0.3752\n",
      "[220]\ttrain-logloss:0.371957\tvalid-logloss:0.37353\n",
      "[230]\ttrain-logloss:0.370393\tvalid-logloss:0.372033\n",
      "[240]\ttrain-logloss:0.368707\tvalid-logloss:0.370371\n",
      "[250]\ttrain-logloss:0.367148\tvalid-logloss:0.368865\n",
      "[260]\ttrain-logloss:0.365737\tvalid-logloss:0.367475\n",
      "[270]\ttrain-logloss:0.364404\tvalid-logloss:0.366195\n",
      "[280]\ttrain-logloss:0.363237\tvalid-logloss:0.36508\n",
      "[290]\ttrain-logloss:0.362141\tvalid-logloss:0.364044\n",
      "[300]\ttrain-logloss:0.361074\tvalid-logloss:0.363046\n",
      "[310]\ttrain-logloss:0.359962\tvalid-logloss:0.362006\n",
      "[320]\ttrain-logloss:0.358912\tvalid-logloss:0.360999\n",
      "[330]\ttrain-logloss:0.357998\tvalid-logloss:0.360131\n",
      "[340]\ttrain-logloss:0.3571\tvalid-logloss:0.359289\n",
      "[350]\ttrain-logloss:0.356202\tvalid-logloss:0.358475\n",
      "[360]\ttrain-logloss:0.355354\tvalid-logloss:0.357722\n",
      "[370]\ttrain-logloss:0.354494\tvalid-logloss:0.356931\n",
      "[380]\ttrain-logloss:0.353653\tvalid-logloss:0.356164\n",
      "[390]\ttrain-logloss:0.352853\tvalid-logloss:0.355452\n"
     ]
    }
   ],
   "source": [
    "# Set our parameters for xgboost\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "d_valid = xgb.DMatrix(X_test, label=Y_test)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=20, verbose_eval=10)\n",
    "\n",
    "\n",
    "\n",
    "xgdmat = xgb.DMatrix(X_train, Y_train) # Create our DMatrix to make XGBoost more efficient\n",
    "#Now let’s specify our parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(X_test)\n",
    "Y_pred = bst.predict(d_test)\n",
    "y_pred = Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40809453  0.28530639  0.12771755 ...,  0.71649224  0.86554301\n",
      "  0.00338006]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print Y_pred\n",
    "for i in range(0,len(Y_pred)):\n",
    "    if Y_pred[i]>=0.5:\n",
    "        Y_pred[i]=1\n",
    "    else:\n",
    "        Y_pred[i]=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45598  5109]\n",
      " [ 9274 20877]]\n"
     ]
    }
   ],
   "source": [
    "conf_xgb = confusion_matrix(Y_test,Y_pred)\n",
    "print conf_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with X-Gboost: 82.2120260209\n"
     ]
    }
   ],
   "source": [
    "true = conf_xgb[0][0]+conf_xgb[1][1]\n",
    "false = conf_xgb[0][1]+conf_xgb[1][0]\n",
    "print \"Test accuracy with X-Gboost:\",float(true)*100/(true+false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 80.3394135304\n",
      "Recall : 69.2414845279\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Precision and recall\n",
    "tn = conf_xgb[0,0]; fp = conf_xgb[0,1]; fn = conf_xgb[1,0]; tp = conf_xgb[1,1];\n",
    "\n",
    "precision = 100*float(tp)/(tp+fp)\n",
    "recall = 100*float(tp)/(tp+fn)\n",
    "\n",
    "print \"Precision :\",precision\n",
    "print \"Recall :\",recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(bst.feature_importances_)\n",
    "feature_imp= bst.get_fscore(fmap='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_Fimp = sorted(feature_imp.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f608', 758),\n",
       " ('f600', 468),\n",
       " ('f601', 444),\n",
       " ('f612', 440),\n",
       " ('f611', 367),\n",
       " ('f622', 293),\n",
       " ('f614', 235),\n",
       " ('f617', 234),\n",
       " ('f623', 202),\n",
       " ('f609', 191),\n",
       " ('f624', 150),\n",
       " ('f613', 110),\n",
       " ('f606', 108),\n",
       " ('f616', 104),\n",
       " ('f405', 59),\n",
       " ('f615', 55),\n",
       " ('f9', 51),\n",
       " ('f105', 50),\n",
       " ('f621', 50),\n",
       " ('f309', 42),\n",
       " ('f189', 40),\n",
       " ('f610', 36),\n",
       " ('f87', 33),\n",
       " ('f620', 33),\n",
       " ('f472', 32),\n",
       " ('f393', 30),\n",
       " ('f269', 25),\n",
       " ('f144', 24),\n",
       " ('f249', 23),\n",
       " ('f172', 22),\n",
       " ('f619', 20),\n",
       " ('f602', 20),\n",
       " ('f559', 19),\n",
       " ('f113', 19),\n",
       " ('f366', 19),\n",
       " ('f607', 19),\n",
       " ('f93', 18),\n",
       " ('f86', 18),\n",
       " ('f207', 18),\n",
       " ('f273', 17),\n",
       " ('f248', 17),\n",
       " ('f82', 16),\n",
       " ('f181', 16),\n",
       " ('f534', 16),\n",
       " ('f276', 15),\n",
       " ('f489', 15),\n",
       " ('f66', 14),\n",
       " ('f292', 13),\n",
       " ('f310', 12),\n",
       " ('f92', 12),\n",
       " ('f618', 12),\n",
       " ('f162', 12),\n",
       " ('f427', 11),\n",
       " ('f10', 11),\n",
       " ('f89', 11),\n",
       " ('f56', 11),\n",
       " ('f296', 11),\n",
       " ('f542', 10),\n",
       " ('f352', 10),\n",
       " ('f241', 10),\n",
       " ('f414', 10),\n",
       " ('f218', 10),\n",
       " ('f569', 9),\n",
       " ('f140', 9),\n",
       " ('f29', 9),\n",
       " ('f270', 8),\n",
       " ('f443', 8),\n",
       " ('f15', 8),\n",
       " ('f38', 8),\n",
       " ('f234', 8),\n",
       " ('f406', 8),\n",
       " ('f589', 7),\n",
       " ('f224', 7),\n",
       " ('f440', 7),\n",
       " ('f389', 7),\n",
       " ('f6', 7),\n",
       " ('f152', 7),\n",
       " ('f386', 7),\n",
       " ('f407', 7),\n",
       " ('f524', 7),\n",
       " ('f592', 7),\n",
       " ('f51', 7),\n",
       " ('f509', 7),\n",
       " ('f458', 7),\n",
       " ('f518', 7),\n",
       " ('f444', 6),\n",
       " ('f268', 6),\n",
       " ('f317', 6),\n",
       " ('f157', 6),\n",
       " ('f2', 6),\n",
       " ('f185', 6),\n",
       " ('f531', 6),\n",
       " ('f116', 6),\n",
       " ('f259', 6),\n",
       " ('f77', 5),\n",
       " ('f78', 5),\n",
       " ('f302', 5),\n",
       " ('f261', 5),\n",
       " ('f146', 5),\n",
       " ('f13', 5),\n",
       " ('f159', 5),\n",
       " ('f382', 5),\n",
       " ('f120', 5),\n",
       " ('f36', 5),\n",
       " ('f30', 5),\n",
       " ('f232', 5),\n",
       " ('f333', 5),\n",
       " ('f536', 5),\n",
       " ('f58', 5),\n",
       " ('f199', 5),\n",
       " ('f420', 5),\n",
       " ('f365', 5),\n",
       " ('f45', 5),\n",
       " ('f452', 5),\n",
       " ('f375', 4),\n",
       " ('f568', 4),\n",
       " ('f272', 4),\n",
       " ('f570', 4),\n",
       " ('f573', 4),\n",
       " ('f572', 4),\n",
       " ('f147', 4),\n",
       " ('f490', 4),\n",
       " ('f97', 4),\n",
       " ('f246', 4),\n",
       " ('f81', 4),\n",
       " ('f413', 4),\n",
       " ('f554', 4),\n",
       " ('f331', 4),\n",
       " ('f485', 4),\n",
       " ('f486', 4),\n",
       " ('f194', 4),\n",
       " ('f586', 4),\n",
       " ('f168', 4),\n",
       " ('f430', 4),\n",
       " ('f537', 4),\n",
       " ('f591', 4),\n",
       " ('f590', 4),\n",
       " ('f50', 4),\n",
       " ('f358', 4),\n",
       " ('f357', 4),\n",
       " ('f459', 4),\n",
       " ('f513', 4),\n",
       " ('f286', 4),\n",
       " ('f502', 4),\n",
       " ('f297', 4),\n",
       " ('f165', 4),\n",
       " ('f364', 3),\n",
       " ('f118', 3),\n",
       " ('f506', 3),\n",
       " ('f307', 3),\n",
       " ('f104', 3),\n",
       " ('f359', 3),\n",
       " ('f265', 3),\n",
       " ('f387', 3),\n",
       " ('f0', 3),\n",
       " ('f251', 3),\n",
       " ('f392', 3),\n",
       " ('f94', 3),\n",
       " ('f243', 3),\n",
       " ('f327', 3),\n",
       " ('f450', 3),\n",
       " ('f122', 3),\n",
       " ('f123', 3),\n",
       " ('f275', 3),\n",
       " ('f34', 3),\n",
       " ('f32', 3),\n",
       " ('f330', 3),\n",
       " ('f135', 3),\n",
       " ('f137', 3),\n",
       " ('f585', 3),\n",
       " ('f178', 3),\n",
       " ('f219', 3),\n",
       " ('f436', 3),\n",
       " ('f596', 3),\n",
       " ('f214', 3),\n",
       " ('f367', 3),\n",
       " ('f164', 3),\n",
       " ('f163', 3),\n",
       " ('f603', 3),\n",
       " ('f74', 2),\n",
       " ('f176', 2),\n",
       " ('f446', 2),\n",
       " ('f63', 2),\n",
       " ('f473', 2),\n",
       " ('f16', 2),\n",
       " ('f493', 2),\n",
       " ('f479', 2),\n",
       " ('f266', 2),\n",
       " ('f150', 2),\n",
       " ('f190', 2),\n",
       " ('f245', 2),\n",
       " ('f324', 2),\n",
       " ('f5', 2),\n",
       " ('f80', 2),\n",
       " ('f125', 2),\n",
       " ('f242', 2),\n",
       " ('f230', 2),\n",
       " ('f182', 2),\n",
       " ('f409', 2),\n",
       " ('f130', 2),\n",
       " ('f404', 2),\n",
       " ('f402', 2),\n",
       " ('f526', 2),\n",
       " ('f28', 2),\n",
       " ('f23', 2),\n",
       " ('f416', 2),\n",
       " ('f109', 2),\n",
       " ('f345', 2),\n",
       " ('f342', 2),\n",
       " ('f503', 2),\n",
       " ('f55', 2),\n",
       " ('f290', 2),\n",
       " ('f355', 2),\n",
       " ('f205', 2),\n",
       " ('f517', 2),\n",
       " ('f284', 2),\n",
       " ('f604', 2),\n",
       " ('f71', 1),\n",
       " ('f79', 1),\n",
       " ('f433', 1),\n",
       " ('f379', 1),\n",
       " ('f562', 1),\n",
       " ('f560', 1),\n",
       " ('f561', 1),\n",
       " ('f565', 1),\n",
       " ('f448', 1),\n",
       " ('f177', 1),\n",
       " ('f179', 1),\n",
       " ('f69', 1),\n",
       " ('f304', 1),\n",
       " ('f308', 1),\n",
       " ('f328', 1),\n",
       " ('f605', 1),\n",
       " ('f346', 1),\n",
       " ('f14', 1),\n",
       " ('f12', 1),\n",
       " ('f492', 1),\n",
       " ('f491', 1),\n",
       " ('f19', 1),\n",
       " ('f497', 1),\n",
       " ('f495', 1),\n",
       " ('f254', 1),\n",
       " ('f252', 1),\n",
       " ('f315', 1),\n",
       " ('f314', 1),\n",
       " ('f238', 1),\n",
       " ('f549', 1),\n",
       " ('f465', 1),\n",
       " ('f539', 1),\n",
       " ('f98', 1),\n",
       " ('f154', 1),\n",
       " ('f320', 1),\n",
       " ('f322', 1),\n",
       " ('f558', 1),\n",
       " ('f415', 1),\n",
       " ('f329', 1),\n",
       " ('f197', 1),\n",
       " ('f385', 1),\n",
       " ('f25', 1),\n",
       " ('f139', 1),\n",
       " ('f338', 1),\n",
       " ('f236', 1),\n",
       " ('f133', 1),\n",
       " ('f401', 1),\n",
       " ('f463', 1),\n",
       " ('f523', 1),\n",
       " ('f287', 1),\n",
       " ('f587', 1),\n",
       " ('f581', 1),\n",
       " ('f482', 1),\n",
       " ('f228', 1),\n",
       " ('f223', 1),\n",
       " ('f438', 1),\n",
       " ('f439', 1),\n",
       " ('f102', 1),\n",
       " ('f533', 1),\n",
       " ('f532', 1),\n",
       " ('f551', 1),\n",
       " ('f318', 1),\n",
       " ('f598', 1),\n",
       " ('f256', 1),\n",
       " ('f59', 1),\n",
       " ('f380', 1),\n",
       " ('f53', 1),\n",
       " ('f213', 1),\n",
       " ('f54', 1),\n",
       " ('f294', 1),\n",
       " ('f353', 1),\n",
       " ('f394', 1),\n",
       " ('f111', 1),\n",
       " ('f408', 1),\n",
       " ('f46', 1),\n",
       " ('f202', 1),\n",
       " ('f206', 1),\n",
       " ('f204', 1),\n",
       " ('f282', 1),\n",
       " ('f462', 1),\n",
       " ('f514', 1),\n",
       " ('f285', 1),\n",
       " ('f166', 1),\n",
       " ('f541', 1)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_Fimp.reverse()\n",
    "sorted_Fimp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

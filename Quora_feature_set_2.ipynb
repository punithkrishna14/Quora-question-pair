{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import distance\n",
    "from bs4 import BeautifulSoup\n",
    "import scipy\n",
    "import re\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contractions_dict = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall\",\n",
    "\"he'll've\": \"he shall have\",\n",
    "\"he's\": \"he has\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"I had\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I will\",\n",
    "\"i'll've\": \"I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they had\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you shall have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    #expand contractions\n",
    "    \n",
    "    def expand_contractions(sentence, contractions_dict=contractions_dict):\n",
    "        def replace(match):\n",
    "            return contractions_dict[match.group(0)]\n",
    "        return contractions_re.sub(replace, sentence)\n",
    "\n",
    "    \n",
    "    #print \"Removing Punctuations and numbers and expanding contractions...\"\n",
    "    pattern = re.compile('\\W')\n",
    "    contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "    \n",
    "    if type(x) == type(''):\n",
    "        x = re.sub(pattern, ' ', x)\n",
    "        x = ''.join([i for i in x if not i.isdigit()])\n",
    "        x = expand_contractions(x)\n",
    "    \n",
    "        \n",
    "    #print \"Removing HTML tags and performing stemming...\"\n",
    "    \n",
    "    if type(x) == type(''):\n",
    "        example1 = BeautifulSoup(x)\n",
    "        x = example1.get_text()\n",
    "               \n",
    "    \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshan_excellence/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning:\n",
      "\n",
      "No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /home/darshan_excellence/anaconda2/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6) (404290, 6)\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "original_shape = pd.read_csv('train.csv').shape\n",
    "print df.shape,original_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([('Hey', 'what'), ('is', 'up?'), ('what', 'is')]) set([('do', 'up'), ('Hey', 'what'), ('is', 'up?'), ('what', 'do'), ('up', 'is')])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "bigrm1 = set(nltk.bigrams(\"Hey what is up?\".split()))\n",
    "bigrm2 = set(nltk.bigrams(\"Hey what do up is up?\".split()))\n",
    "print bigrm1,bigrm2\n",
    "len(bigrm1&bigrm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "test = df.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigram_word_Common(row):\n",
    "    w1 = set(nltk.bigrams(row['question1'].split(\" \")))\n",
    "    w2 = set(nltk.bigrams(row['question2'].split(\" \")))\n",
    "    return 1.0 * len(w1 & w2)\n",
    "\n",
    "df['bigram_common'] = df.apply(bigram_word_Common,axis = 1)\n",
    "\n",
    "def bigram_word_total(row):\n",
    "    w1 = set(nltk.bigrams(row['question1'].split(\" \")))\n",
    "    w2 = set(nltk.bigrams(row['question2'].split(\" \")))\n",
    "    return 1.0 * ((len(w1)+len(w2)) - 1.0 * len(w1 & w2))\n",
    "\n",
    "df['bigram_total'] = df.apply(bigram_word_total,axis = 1)\n",
    "\n",
    "df['bigram_ratio'] = df['bigram_common']/df['bigram_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darshan_excellence/.local/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'how can i increase the speed of my internet connection while using a vpn  how can internet speed be increased by hacking through dns '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['combined'] = test['question1']+\" \"+test['question2']\n",
    "test['combined'].loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "df['combined'] = df['question1']+\" \"+df['question2']\n",
    "\n",
    "tfidf_combined = v.fit_transform(df['combined'].values)\n",
    "word_vec = np.array(v.get_feature_names())\n",
    "\n",
    "tfidf_rows = [tfidf_combined[i,:] for i in range(0,df.shape[0])]\n",
    "df['tfidf'] = tfidf_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>bigram_common</th>\n",
       "      <th>bigram_total</th>\n",
       "      <th>bigram_ratio</th>\n",
       "      <th>combined</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>tfidf_unigram_word_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>(0, 77556)\\t0.0756699844518\\n  (0, 35701)\\t0...</td>\n",
       "      <td>0.966742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>(0, 77556)\\t0.0701848729964\\n  (0, 35701)\\t0...</td>\n",
       "      <td>0.650728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>(0, 70831)\\t0.0540481138459\\n  (0, 10064)\\t0...</td>\n",
       "      <td>0.301877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely  how can i solve...</td>\n",
       "      <td>find the remainder when  math      math  is di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>why am i mentally very lonely  how can i solve...</td>\n",
       "      <td>(0, 35701)\\t0.0668356636523\\n  (0, 70831)\\t0...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>(0, 33839)\\t0.116120577565\\n  (0, 78429)\\t0....</td>\n",
       "      <td>0.293379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely  how can i solve...   \n",
       "4   4     9    10  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  what is the step by step guide to invest in sh...             0   \n",
       "1  what would happen if the indian government sto...             0   \n",
       "2  how can internet speed be increased by hacking...             0   \n",
       "3  find the remainder when  math      math  is di...             0   \n",
       "4            which fish would survive in salt water              0   \n",
       "\n",
       "   bigram_common  bigram_total  bigram_ratio  \\\n",
       "0           11.0          15.0      0.733333   \n",
       "1            6.0          23.0      0.260870   \n",
       "2            1.0          23.0      0.043478   \n",
       "3            0.0          23.0      0.000000   \n",
       "4            0.0          22.0      0.000000   \n",
       "\n",
       "                                            combined  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1  what is the story of kohinoor  koh i noor  dia...   \n",
       "2  how can i increase the speed of my internet co...   \n",
       "3  why am i mentally very lonely  how can i solve...   \n",
       "4  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                               tfidf  tfidf_unigram_word_match  \n",
       "0    (0, 77556)\\t0.0756699844518\\n  (0, 35701)\\t0...                  0.966742  \n",
       "1    (0, 77556)\\t0.0701848729964\\n  (0, 35701)\\t0...                  0.650728  \n",
       "2    (0, 70831)\\t0.0540481138459\\n  (0, 10064)\\t0...                  0.301877  \n",
       "3    (0, 35701)\\t0.0668356636523\\n  (0, 70831)\\t0...                  0.000000  \n",
       "4    (0, 33839)\\t0.116120577565\\n  (0, 78429)\\t0....                  0.293379  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf_unigram_word_match(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "\n",
    "    common_words = [words for words in (w1 & w2) if words != '' and len(words)>1] \n",
    "    if common_words == []:\n",
    "        return 0\n",
    "\n",
    "    else:\n",
    "        tfidf_scores = scipy.sparse.find(row['tfidf'])\n",
    "        common_word_ind = [np.where(word_vec == ind)[0][0] for ind in common_words]\n",
    "        tfidf_common_sum = sum([tfidf_scores[2][i] for i in range(0,len(tfidf_scores[1])) if tfidf_scores[1][i] in common_word_ind])\n",
    "        return 1.0*(tfidf_common_sum/sum(tfidf_scores[2]))\n",
    "\n",
    "    \n",
    "df['tfidf_unigram_word_match'] = df.apply(tfidf_unigram_word_match,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here\n",
    "from functools import reduce\n",
    "def normalized_word_Common(row):\n",
    "\n",
    "    w1 = set(map(lambda word: word_vec.value().index(\"daiict\") , Common_words))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return  w1 & w2\n",
    "    \n",
    "    map(lambda word: word.lower().strip(), row['question2'].split(\" \"))\n",
    "    sum = reduce((lambda x, y: x + y), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> word_Total =(Total num of words in Question 1 + Total num of words in Question 2)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "def normalized_word_Common(row):\n",
    "\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return 1.0 * len(w1 & w2)\n",
    "\n",
    "df['word_Common'] = df.apply(normalized_word_Common, axis=1)\n",
    "\n",
    "def normalized_word_Total(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return 1.0 * (len(w1) + len(w2))\n",
    "\n",
    "\n",
    "\n",
    "df['word_Total'] = df.apply(normalized_word_Total, axis=1)\n",
    "\n",
    "print \"\\n-> word_Total =(Total num of words in Question 1 + Total num of words in Question 2)\"\n",
    "\n",
    "def normalized_word_share(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
    "\n",
    "\n",
    "\n",
    "df['word_share'] = df.apply(normalized_word_share, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> freq_qid1 = frequency of qid1's\n",
      "\n",
      "-> freq_qid2 = frequency of qid2's \n",
      "\n",
      "-> q1len = Length of q1\n",
      "\n",
      "-> q2len = Length of q2\n",
      "\n",
      "-> q1_n_words = num of words i Question 1\n",
      "\n",
      "-> q2_n_words = num of words i Question 2\n",
      "\n",
      "-> word_Common = (num of common unique words in Question 1 and Question 2)\n",
      "\n",
      "-> word_Total =(Total num of words in Question 1 + Total num of words in Question 2)\n",
      "\n",
      "-> word_share = (num of common unique words in Question 1 and Question 2)/(Total num of words in Question 1 + Total num of words in Question 2)\n",
      "\n",
      "\n",
      "-> freq_q1+q2 = sum total of frequency of qid1 and qid2 \n",
      "\n",
      "-> freq_q1-q2 = absolute difference of frequency of qid1 and qid2 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>bigram_common</th>\n",
       "      <th>bigram_total</th>\n",
       "      <th>bigram_ratio</th>\n",
       "      <th>combined</th>\n",
       "      <th>...</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "      <th>capital_1</th>\n",
       "      <th>capital_2</th>\n",
       "      <th>capital_total</th>\n",
       "      <th>capital_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely  how can i solve...</td>\n",
       "      <td>find the remainder when  math      math  is di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>why am i mentally very lonely  how can i solve...</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely  how can i solve...   \n",
       "4   4     9    10  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  what is the step by step guide to invest in sh...             0   \n",
       "1  what would happen if the indian government sto...             0   \n",
       "2  how can internet speed be increased by hacking...             0   \n",
       "3  find the remainder when  math      math  is di...             0   \n",
       "4            which fish would survive in salt water              0   \n",
       "\n",
       "   bigram_common  bigram_total  bigram_ratio  \\\n",
       "0           11.0          15.0      0.733333   \n",
       "1            6.0          23.0      0.260870   \n",
       "2            1.0          23.0      0.043478   \n",
       "3            0.0          23.0      0.000000   \n",
       "4            0.0          22.0      0.000000   \n",
       "\n",
       "                                            combined      ...      q1len  \\\n",
       "0  what is the step by step guide to invest in sh...      ...         66   \n",
       "1  what is the story of kohinoor  koh i noor  dia...      ...         51   \n",
       "2  how can i increase the speed of my internet co...      ...         73   \n",
       "3  why am i mentally very lonely  how can i solve...      ...         50   \n",
       "4  which one dissolve in water quikly sugar  salt...      ...         76   \n",
       "\n",
       "   q2len  q1_n_words  q2_n_words  freq_q1+q2  freq_q1-q2  capital_1  \\\n",
       "0     57          15          13           2           0        1.0   \n",
       "1     88          13          18           5           3        5.0   \n",
       "2     59          15          11           2           0        5.0   \n",
       "3     57          13          19           2           0        4.0   \n",
       "4     39          16           8           4           2        1.0   \n",
       "\n",
       "   capital_2  capital_total  capital_diff  \n",
       "0        0.0            0.0           0.0  \n",
       "1        0.0            0.0           0.0  \n",
       "2        0.0            0.0           0.0  \n",
       "3        0.0            0.0           0.0  \n",
       "4        0.0            0.0           0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def bigram_word_Common(row):\n",
    "#    w1 = set(nltk.bigrams(row['question1'].split(\" \")).split())\n",
    "#    w2 = set(nltk.bigrams(row['question2'].split(\" \")).split())\n",
    "#    return 1.0 * len(w1 & w2)\n",
    "\n",
    "#df['bigram_common'] = df.apply(bigram_word_Common, axis=1)\n",
    "\n",
    "df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count') \n",
    "\n",
    "print \"-> freq_qid1 = frequency of qid1's\"\n",
    "\n",
    "df['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count')\n",
    "\n",
    "print \"\\n-> freq_qid2 = frequency of qid2's \"\n",
    "\n",
    "df['q1len'] = df['question1'].str.len() \n",
    "\n",
    "print \"\\n-> q1len = Length of q1\"\n",
    "\n",
    "df['q2len'] = df['question2'].str.len()\n",
    "\n",
    "print \"\\n-> q2len = Length of q2\"\n",
    "\n",
    "df['q1_n_words'] = df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "\n",
    "print \"\\n-> q1_n_words = num of words i Question 1\"\n",
    "# how lambda is workiing\n",
    "df['q2_n_words'] = df['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "\n",
    "print \"\\n-> q2_n_words = num of words i Question 2\"\n",
    "\n",
    "\n",
    "\n",
    "def normalized_word_Common(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return 1.0 * len(w1 & w2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['word_Common'] = df.apply(normalized_word_Common, axis=1)\n",
    "\n",
    "print \"\\n-> word_Common = (num of common unique words in Question 1 and Question 2)\"\n",
    "\n",
    "def normalized_word_Total(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return 1.0 * (len(w1) + len(w2))\n",
    "\n",
    "\n",
    "\n",
    "df['word_Total'] = df.apply(normalized_word_Total, axis=1)\n",
    "\n",
    "print \"\\n-> word_Total =(Total num of words in Question 1 + Total num of words in Question 2)\"\n",
    "\n",
    "def normalized_word_share(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
    "\n",
    "\n",
    "\n",
    "df['word_share'] = df.apply(normalized_word_share, axis=1)\n",
    "\n",
    "print \"\\n-> word_share = (num of common unique words in Question 1 and Question 2)/(Total num of words in Question 1 + Total num of words in Question 2)\\n\"\n",
    "\n",
    "print \"\\n-> freq_q1+q2 = sum total of frequency of qid1 and qid2 \"\n",
    "\n",
    "print \"\\n-> freq_q1-q2 = absolute difference of frequency of qid1 and qid2 \"\n",
    "\n",
    "df['freq_q1+q2'] = df['freq_qid1']+df['freq_qid2']\n",
    "df['freq_q1-q2'] = abs(df['freq_qid1']-df['freq_qid2'])\n",
    "\n",
    "#Bigrams\n",
    "def bigram_word_Common(row):\n",
    "    w1 = set(nltk.bigrams(row['question1'].split(\" \")))\n",
    "    w2 = set(nltk.bigrams(row['question2'].split(\" \")))\n",
    "    return 1.0 * len(w1 & w2)\n",
    "\n",
    "df['bigram_common'] = df.apply(bigram_word_Common,axis = 1)\n",
    "\n",
    "def bigram_word_total(row):\n",
    "    w1 = set(nltk.bigrams(row['question1'].split(\" \")))\n",
    "    w2 = set(nltk.bigrams(row['question2'].split(\" \")))\n",
    "    return 1.0 * ((len(w1)+len(w2)) - 1.0 * len(w1 & w2))\n",
    "\n",
    "df['bigram_total'] = df.apply(bigram_word_total,axis = 1)\n",
    "\n",
    "df['bigram_ratio'] = df['bigram_common']/df['bigram_total']\n",
    "\n",
    "\n",
    "df.to_csv(\"df_fe2_preprocessing_train.csv\", index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>bigram_common</th>\n",
       "      <th>bigram_total</th>\n",
       "      <th>bigram_ratio</th>\n",
       "      <th>combined</th>\n",
       "      <th>...</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "      <th>capital_1</th>\n",
       "      <th>capital_2</th>\n",
       "      <th>capital_total</th>\n",
       "      <th>capital_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely  how can i solve...</td>\n",
       "      <td>find the remainder when  math      math  is di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>why am i mentally very lonely  how can i solve...</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely  how can i solve...   \n",
       "4   4     9    10  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  what is the step by step guide to invest in sh...             0   \n",
       "1  what would happen if the indian government sto...             0   \n",
       "2  how can internet speed be increased by hacking...             0   \n",
       "3  find the remainder when  math      math  is di...             0   \n",
       "4            which fish would survive in salt water              0   \n",
       "\n",
       "   bigram_common  bigram_total  bigram_ratio  \\\n",
       "0           11.0          15.0      0.733333   \n",
       "1            6.0          23.0      0.260870   \n",
       "2            1.0          23.0      0.043478   \n",
       "3            0.0          23.0      0.000000   \n",
       "4            0.0          22.0      0.000000   \n",
       "\n",
       "                                            combined      ...      q1len  \\\n",
       "0  what is the step by step guide to invest in sh...      ...         66   \n",
       "1  what is the story of kohinoor  koh i noor  dia...      ...         51   \n",
       "2  how can i increase the speed of my internet co...      ...         73   \n",
       "3  why am i mentally very lonely  how can i solve...      ...         50   \n",
       "4  which one dissolve in water quikly sugar  salt...      ...         76   \n",
       "\n",
       "   q2len  q1_n_words  q2_n_words  freq_q1+q2  freq_q1-q2  capital_1  \\\n",
       "0     57          15          13           2           0        0.0   \n",
       "1     88          13          18           5           3        0.0   \n",
       "2     59          15          11           2           0        0.0   \n",
       "3     57          13          19           2           0        0.0   \n",
       "4     39          16           8           4           2        0.0   \n",
       "\n",
       "   capital_2  capital_total  capital_diff  \n",
       "0        0.0            0.0           0.0  \n",
       "1        0.0            0.0           0.0  \n",
       "2        0.0            0.0           0.0  \n",
       "3        0.0            0.0           0.0  \n",
       "4        0.0            0.0           0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_token_features(q1, q2):\n",
    "    token_features = [0.0]*10\n",
    "    \n",
    "    # Converting the Sentence of Que. in the Tokens\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "\n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    # Last word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    # First word of both question is same or not\n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    return token_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the Longest Common sub string\n",
    "\n",
    "def get_longest_substr_ratio(a, b):\n",
    "    strs = list(distance.lcsubstrings(a, b))\n",
    "    if len(strs) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a), len(b)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "\n",
    "    print(\"token features...\")\n",
    "    \n",
    "    # Merging Features with dataset\n",
    "    \n",
    "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    \n",
    "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
    "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
    "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
    "   \n",
    "    #Computing Fuzzy Features and Merging with Dataset\n",
    "    print(\"fuzzy features..\")\n",
    "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Extracting features for train:\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df = extract_features(train_df)\n",
    "#train_df.drop([\"id\", \"qid1\", \"qid2\", \"question1\", \"question2\", \"is_duplicate\"], axis=1, inplace=True)\n",
    "\n",
    "# Creating new .csv File with total 21 features:\n",
    "train_df.to_csv(\"nlp_features_train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
